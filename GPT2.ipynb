{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2d924fd65274dd2aaed9c0bc0fc3271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bda80d17a1f84458bdac87466bfcff8e",
              "IPY_MODEL_dae287d64a204b0687fd1fe62eeeeb09",
              "IPY_MODEL_9b1c100860ce45019abe0bf24d6843ed"
            ],
            "layout": "IPY_MODEL_b4a46c247b634b58b0367cd141c2cf6b"
          }
        },
        "bda80d17a1f84458bdac87466bfcff8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc5d4d1d6d043499855e2bf8a4ea463",
            "placeholder": "​",
            "style": "IPY_MODEL_929c43f435db40aeb4f6ade8f050994b",
            "value": "vocab.json: 100%"
          }
        },
        "dae287d64a204b0687fd1fe62eeeeb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab088f5fde744757941a578f37f38286",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ddf38d04c54273bde320124285cd72",
            "value": 1042301
          }
        },
        "9b1c100860ce45019abe0bf24d6843ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554475bee99248f7b0e432c143b703af",
            "placeholder": "​",
            "style": "IPY_MODEL_37c4613dd9fb4427851715fffa6737fb",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.49MB/s]"
          }
        },
        "b4a46c247b634b58b0367cd141c2cf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc5d4d1d6d043499855e2bf8a4ea463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929c43f435db40aeb4f6ade8f050994b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab088f5fde744757941a578f37f38286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ddf38d04c54273bde320124285cd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "554475bee99248f7b0e432c143b703af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c4613dd9fb4427851715fffa6737fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d27a8948aa5041b29939b8b65e478ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51da4d8f6c1f4a7aa204896ea9ca98ed",
              "IPY_MODEL_7309717c2938483a8bdf5dc5e359e6a4",
              "IPY_MODEL_97661c2334f3429ea972f5f0e90f531b"
            ],
            "layout": "IPY_MODEL_46a7a554c1484a298c7c76f2d65d5f6b"
          }
        },
        "51da4d8f6c1f4a7aa204896ea9ca98ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e83f8e778ef2492f9cc5002bf37c04a5",
            "placeholder": "​",
            "style": "IPY_MODEL_77938c73037a48edb5e0431ffb9310ab",
            "value": "merges.txt: 100%"
          }
        },
        "7309717c2938483a8bdf5dc5e359e6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b6d96358bc478aa64c26523877aead",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1773c9d45a444bf4b30963e6fbf6f3d6",
            "value": 456318
          }
        },
        "97661c2334f3429ea972f5f0e90f531b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cbafb6e093b42fba3c78a8c0821bb90",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4bcd31ea764c828c92121972f9c6d7",
            "value": " 456k/456k [00:00&lt;00:00, 8.66MB/s]"
          }
        },
        "46a7a554c1484a298c7c76f2d65d5f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83f8e778ef2492f9cc5002bf37c04a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77938c73037a48edb5e0431ffb9310ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b6d96358bc478aa64c26523877aead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1773c9d45a444bf4b30963e6fbf6f3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cbafb6e093b42fba3c78a8c0821bb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4bcd31ea764c828c92121972f9c6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec434050dc304c1ba02a1efdbebb1e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35814ed0a90d43409eda082a1ecba3ff",
              "IPY_MODEL_121eb159c8f54b4aa8975e0ba060c366",
              "IPY_MODEL_a77b6ac86c8444bab94370d29c8625f8"
            ],
            "layout": "IPY_MODEL_0def6c3254af4e8bb755ec7b578df88c"
          }
        },
        "35814ed0a90d43409eda082a1ecba3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998af8dbd19e4d69abf8b3dd2030b130",
            "placeholder": "​",
            "style": "IPY_MODEL_9a7be81947bf4a6cbe6168b27c66565d",
            "value": "tokenizer.json: 100%"
          }
        },
        "121eb159c8f54b4aa8975e0ba060c366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_611d128ad9dd40eb97dca60c1fabbb69",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b64c4b118740a1ab9659bb9fe28d5b",
            "value": 1355256
          }
        },
        "a77b6ac86c8444bab94370d29c8625f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8fbe13a9c594e6ea85628fd3eec50c8",
            "placeholder": "​",
            "style": "IPY_MODEL_6d244b94100840bca52e855c4788193a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 24.3MB/s]"
          }
        },
        "0def6c3254af4e8bb755ec7b578df88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998af8dbd19e4d69abf8b3dd2030b130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7be81947bf4a6cbe6168b27c66565d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "611d128ad9dd40eb97dca60c1fabbb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b64c4b118740a1ab9659bb9fe28d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8fbe13a9c594e6ea85628fd3eec50c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d244b94100840bca52e855c4788193a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12949759eb0946eaaf37cef04f022220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b80e16b258a2451e86f61bd5fd8a9808",
              "IPY_MODEL_b92ed473191d4db8940cb5c1208eb597",
              "IPY_MODEL_5d8620ed4aee4cefbaacc993edf9cf0c"
            ],
            "layout": "IPY_MODEL_ea42e44589f84febaa5b800b2818ee41"
          }
        },
        "b80e16b258a2451e86f61bd5fd8a9808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7ec41527db47e0b9904828ba95551c",
            "placeholder": "​",
            "style": "IPY_MODEL_063115ee0f2742aa9db4968aa2e09e8e",
            "value": "config.json: 100%"
          }
        },
        "b92ed473191d4db8940cb5c1208eb597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce485aaf0d16437d95faf713539ddab3",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ada5109c005407aa6d6435e9a031be4",
            "value": 665
          }
        },
        "5d8620ed4aee4cefbaacc993edf9cf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9e5e18f4d01438f8c4544a5230bfc26",
            "placeholder": "​",
            "style": "IPY_MODEL_b1179a48df2143818f46949de077b497",
            "value": " 665/665 [00:00&lt;00:00, 8.00kB/s]"
          }
        },
        "ea42e44589f84febaa5b800b2818ee41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7ec41527db47e0b9904828ba95551c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063115ee0f2742aa9db4968aa2e09e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce485aaf0d16437d95faf713539ddab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ada5109c005407aa6d6435e9a031be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9e5e18f4d01438f8c4544a5230bfc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1179a48df2143818f46949de077b497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7775814d23b14cb0b082e1ef13f5827c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd0ce53bf62047628ef806ebdc09e705",
              "IPY_MODEL_c0ba92c3180d492f8fc347f185e320a5",
              "IPY_MODEL_e0b8735bf9fd450a992d00746e9a4897"
            ],
            "layout": "IPY_MODEL_91274fb6966247f88fc72b87d7a40a3f"
          }
        },
        "fd0ce53bf62047628ef806ebdc09e705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1cc2679c0048ffac37315312f27aef",
            "placeholder": "​",
            "style": "IPY_MODEL_5aeed906f6294d6ab20ec8a25a2c97f2",
            "value": "model.safetensors: 100%"
          }
        },
        "c0ba92c3180d492f8fc347f185e320a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf9f97bf008f4a049f03dc12584dda49",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26f78598c49e4147a5ea27756ed0381b",
            "value": 548105171
          }
        },
        "e0b8735bf9fd450a992d00746e9a4897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1815532542422fbc6eaac855c83914",
            "placeholder": "​",
            "style": "IPY_MODEL_478af5360b214a9ea868853a79bba2a4",
            "value": " 548M/548M [00:05&lt;00:00, 106MB/s]"
          }
        },
        "91274fb6966247f88fc72b87d7a40a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1cc2679c0048ffac37315312f27aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aeed906f6294d6ab20ec8a25a2c97f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf9f97bf008f4a049f03dc12584dda49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f78598c49e4147a5ea27756ed0381b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf1815532542422fbc6eaac855c83914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478af5360b214a9ea868853a79bba2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffdda514e584820b61680fb32aba391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f64f1d5608394cd0bc7b9cb9f5934dc4",
              "IPY_MODEL_b8b2ffeae3d44b4b8b612574e73cbfab",
              "IPY_MODEL_9d12ae3adfd94b31a0cb5b8d2bff789b"
            ],
            "layout": "IPY_MODEL_fdf4e7d4922f477baa7e099283cf6c15"
          }
        },
        "f64f1d5608394cd0bc7b9cb9f5934dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bfcc74094534981b3be8682de55b894",
            "placeholder": "​",
            "style": "IPY_MODEL_92d00caae0cd443789498e9be5a78ef5",
            "value": "generation_config.json: 100%"
          }
        },
        "b8b2ffeae3d44b4b8b612574e73cbfab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e2aa26223f42008fa7ad90884f1f59",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16987bd817464ba1bdc840f64aeb687c",
            "value": 124
          }
        },
        "9d12ae3adfd94b31a0cb5b8d2bff789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760e8419dd044009a2c3362e3790cc5f",
            "placeholder": "​",
            "style": "IPY_MODEL_6a0d1d1be6a94fbe918c7bf91d1a832d",
            "value": " 124/124 [00:00&lt;00:00, 3.36kB/s]"
          }
        },
        "fdf4e7d4922f477baa7e099283cf6c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfcc74094534981b3be8682de55b894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d00caae0cd443789498e9be5a78ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e2aa26223f42008fa7ad90884f1f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16987bd817464ba1bdc840f64aeb687c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "760e8419dd044009a2c3362e3790cc5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0d1d1be6a94fbe918c7bf91d1a832d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Q and A\n",
        "Q1\n",
        "#for non duplicate features weight will be same but for duplicate features weight will be halved as summation  of that duplicate and original will be same as initial one before duplicate"
      ],
      "metadata": {
        "id": "feJyDxJku23E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q and A\n",
        "Q1\n",
        "#for non duplicate features weight will be same but for duplicate features weight will be halved as summation  of that duplicate and original will be same as initial one before duplicate\n",
        "Woriginal/2 = Wnew  for duplicate feature\n",
        "\n",
        "\n",
        "else\n",
        "Wold = Wnew\n"
      ],
      "metadata": {
        "id": "MvgkH3Rmv3Pe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2\n",
        "\n",
        "B option\n",
        "\n",
        "E is better than A with over 95% confidence, B is worse than A with over 95% confidence. You need to run the test for longer to tell where C and D compare to A with 95% confidence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ezkaU3DmwFVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3\n",
        "\n",
        "O(mk + nk)"
      ],
      "metadata": {
        "id": "aOUemRymwidm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n",
        "\n",
        "Ranking: C (best), A, B(worst)\n"
      ],
      "metadata": {
        "id": "9B-xUeH9xGS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5\n",
        "\n",
        "\n",
        "For MLE =\n",
        "\n",
        " p = k / n\n",
        "\n",
        "bayesian  \n",
        "\n",
        "E[p | k, n] = ∫ p * P(p | k, n) dp\n",
        "\n",
        "\n",
        "\n",
        "MAP\n",
        "\n",
        "p = argmax_p P(p | k, n)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1is6EBnQxNTi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcdkm8v0xFfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task-1"
      ],
      "metadata": {
        "id": "jUe6eoZDCSUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPNw3Xclhjnv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iXn2-hOaZH7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = random.randint(0, 2147483647)\n",
        "np.random.seed(seed)\n",
        "torch.random.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "cmCDO09gzwN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTCLaKhbR9wN",
        "outputId": "9becc14f-068e-478f-df3b-4bb465e57b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model_parameters = model.parameters()\n",
        "\n",
        "# Calculate the total number of parameters\n",
        "total_params = sum(p.numel() for p in model_parameters if p.requires_grad)\n",
        "print(total_params)\n",
        "# Set the model to evaluation mode\n",
        "\n",
        "# Define a prompt for text generation\n",
        "prompt_text = \"Once upon a time\"\n",
        "\n",
        "# Tokenize the prompt\n",
        "input_ids = tokenizer.encode(prompt_text, return_tensors='pt')\n",
        "\n",
        "# Generate text continuation based on the input\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids, max_length=80, num_return_sequences=1)\n",
        "\n",
        "# Decode the generated sequence to obtain the text output\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)\n",
        "#print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "e2d924fd65274dd2aaed9c0bc0fc3271",
            "bda80d17a1f84458bdac87466bfcff8e",
            "dae287d64a204b0687fd1fe62eeeeb09",
            "9b1c100860ce45019abe0bf24d6843ed",
            "b4a46c247b634b58b0367cd141c2cf6b",
            "bcc5d4d1d6d043499855e2bf8a4ea463",
            "929c43f435db40aeb4f6ade8f050994b",
            "ab088f5fde744757941a578f37f38286",
            "53ddf38d04c54273bde320124285cd72",
            "554475bee99248f7b0e432c143b703af",
            "37c4613dd9fb4427851715fffa6737fb",
            "d27a8948aa5041b29939b8b65e478ea9",
            "51da4d8f6c1f4a7aa204896ea9ca98ed",
            "7309717c2938483a8bdf5dc5e359e6a4",
            "97661c2334f3429ea972f5f0e90f531b",
            "46a7a554c1484a298c7c76f2d65d5f6b",
            "e83f8e778ef2492f9cc5002bf37c04a5",
            "77938c73037a48edb5e0431ffb9310ab",
            "d1b6d96358bc478aa64c26523877aead",
            "1773c9d45a444bf4b30963e6fbf6f3d6",
            "8cbafb6e093b42fba3c78a8c0821bb90",
            "8a4bcd31ea764c828c92121972f9c6d7",
            "ec434050dc304c1ba02a1efdbebb1e84",
            "35814ed0a90d43409eda082a1ecba3ff",
            "121eb159c8f54b4aa8975e0ba060c366",
            "a77b6ac86c8444bab94370d29c8625f8",
            "0def6c3254af4e8bb755ec7b578df88c",
            "998af8dbd19e4d69abf8b3dd2030b130",
            "9a7be81947bf4a6cbe6168b27c66565d",
            "611d128ad9dd40eb97dca60c1fabbb69",
            "d8b64c4b118740a1ab9659bb9fe28d5b",
            "d8fbe13a9c594e6ea85628fd3eec50c8",
            "6d244b94100840bca52e855c4788193a",
            "12949759eb0946eaaf37cef04f022220",
            "b80e16b258a2451e86f61bd5fd8a9808",
            "b92ed473191d4db8940cb5c1208eb597",
            "5d8620ed4aee4cefbaacc993edf9cf0c",
            "ea42e44589f84febaa5b800b2818ee41",
            "7f7ec41527db47e0b9904828ba95551c",
            "063115ee0f2742aa9db4968aa2e09e8e",
            "ce485aaf0d16437d95faf713539ddab3",
            "7ada5109c005407aa6d6435e9a031be4",
            "e9e5e18f4d01438f8c4544a5230bfc26",
            "b1179a48df2143818f46949de077b497",
            "7775814d23b14cb0b082e1ef13f5827c",
            "fd0ce53bf62047628ef806ebdc09e705",
            "c0ba92c3180d492f8fc347f185e320a5",
            "e0b8735bf9fd450a992d00746e9a4897",
            "91274fb6966247f88fc72b87d7a40a3f",
            "8f1cc2679c0048ffac37315312f27aef",
            "5aeed906f6294d6ab20ec8a25a2c97f2",
            "cf9f97bf008f4a049f03dc12584dda49",
            "26f78598c49e4147a5ea27756ed0381b",
            "cf1815532542422fbc6eaac855c83914",
            "478af5360b214a9ea868853a79bba2a4",
            "5ffdda514e584820b61680fb32aba391",
            "f64f1d5608394cd0bc7b9cb9f5934dc4",
            "b8b2ffeae3d44b4b8b612574e73cbfab",
            "9d12ae3adfd94b31a0cb5b8d2bff789b",
            "fdf4e7d4922f477baa7e099283cf6c15",
            "2bfcc74094534981b3be8682de55b894",
            "92d00caae0cd443789498e9be5a78ef5",
            "70e2aa26223f42008fa7ad90884f1f59",
            "16987bd817464ba1bdc840f64aeb687c",
            "760e8419dd044009a2c3362e3790cc5f",
            "6a0d1d1be6a94fbe918c7bf91d1a832d"
          ]
        },
        "id": "EvGgshK93jJL",
        "outputId": "749d9d28-be8e-4b12-d319-64e17f72ba74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d924fd65274dd2aaed9c0bc0fc3271"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d27a8948aa5041b29939b8b65e478ea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec434050dc304c1ba02a1efdbebb1e84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12949759eb0946eaaf37cef04f022220"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7775814d23b14cb0b082e1ef13f5827c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ffdda514e584820b61680fb32aba391"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124439808\n",
            "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "gwXzp_nk7NYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342e1bd8-b0ff-46bc-cc5b-6561b98ad02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "class Conv1D(nn.Module):\n",
        "    def __init__(self, nf, nx):\n",
        "        super(Conv1D, self).__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = Parameter(w)\n",
        "        self.bias = Parameter(torch.zeros(nf))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size_out = x.size()[:-1] + (self.nf,)\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(*size_out)\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx,  scale=False):\n",
        "        super(Attention, self).__init__()\n",
        "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
        "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
        "        assert n_state % 12 == 0\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.n_head = 12\n",
        "        self.split_size = n_state\n",
        "        self.scale = scale\n",
        "        self.c_attn = Conv1D(n_state * 3, nx)\n",
        "        self.c_proj = Conv1D(n_state, nx)\n",
        "\n",
        "    def _attn(self, q, k, v):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        b = self.bias[:, :, ns-nd:ns, :ns]\n",
        "        w = w * b - 1e10 * (1 - b)\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        return torch.matmul(w, v)\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "        query = self.split_heads(query)\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
        "        a = self._attn(query, key, value)\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "        return a, present\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_state):  # in MLP: n_state=3072 (4 * n_embd)\n",
        "        super(MLP, self).__init__()\n",
        "        nx = 768\n",
        "        self.c_fc = Conv1D(3072, nx)\n",
        "        self.c_proj = Conv1D(nx, 3072)\n",
        "        self.act = gelu\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.act(self.c_fc(x))\n",
        "        h2 = self.c_proj(h)\n",
        "        return h2\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_ctx=1024, scale=False):\n",
        "        super(Block, self).__init__()\n",
        "        nx = 768\n",
        "        self.ln_1 = LayerNorm(nx, 1e-5)\n",
        "        self.attn = Attention(nx,1024,scale)\n",
        "        self.ln_2 = LayerNorm(nx, eps=1e-5)\n",
        "        self.mlp = MLP(4 * nx)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        a, present = self.attn(self.ln_1(x), layer_past=layer_past)\n",
        "        x = x + a\n",
        "        m = self.mlp(self.ln_2(x))\n",
        "        x = x + m\n",
        "        return x, present\n",
        "\n",
        "class GPT2Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GPT2Model, self).__init__()\n",
        "        self.n_layer = 12\n",
        "        self.n_embd = 768\n",
        "        self.n_vocab = 50257\n",
        "\n",
        "        self.wte = nn.Embedding(50257, 768)\n",
        "        self.wpe = nn.Embedding(1024, 768)\n",
        "        block = Block(1024, scale=True)\n",
        "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(12)])\n",
        "        self.ln_f = LayerNorm(768, 1e-5)\n",
        "\n",
        "    def set_embeddings_weights(self, model_embeddings_weights):\n",
        "        embed_shape = model_embeddings_weights.shape\n",
        "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
        "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, token_type_ids=None, past=None):\n",
        "        if past is None:\n",
        "            past_length = 0\n",
        "            past = [None] * len(self.h)\n",
        "        else:\n",
        "            past_length = past[0][0].size(-2)\n",
        "        if position_ids is None:\n",
        "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\n",
        "                                        device=input_ids.device)\n",
        "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "\n",
        "        input_shape = input_ids.size()\n",
        "        input_ids = input_ids.view(-1, input_ids.size(-1))\n",
        "        position_ids = position_ids.view(-1, position_ids.size(-1))\n",
        "\n",
        "        inputs_embeds = self.wte(input_ids)\n",
        "        position_embeds = self.wpe(position_ids)\n",
        "        if token_type_ids is not None:\n",
        "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
        "            token_type_embeds = self.wte(token_type_ids)\n",
        "        else:\n",
        "            token_type_embeds = 0\n",
        "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
        "        presents = []\n",
        "        for block, layer_past in zip(self.h, past):\n",
        "            hidden_states, present = block(hidden_states, layer_past)\n",
        "            presents.append(present)\n",
        "        hidden_states = self.ln_f(hidden_states)\n",
        "        output_shape = input_shape + (hidden_states.size(-1),)\n",
        "        return hidden_states.view(*output_shape), presents\n",
        "\n",
        "class GPT2LMHead(nn.Module):\n",
        "    def __init__(self, model_embeddings_weights):\n",
        "        super(GPT2LMHead, self).__init__()\n",
        "        self.n_embd = 768\n",
        "        self.set_embeddings_weights(model_embeddings_weights)\n",
        "\n",
        "    def set_embeddings_weights(self, model_embeddings_weights):\n",
        "        embed_shape = model_embeddings_weights.shape\n",
        "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
        "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        # Truncated Language modeling logits (we remove the last token)\n",
        "        # h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
        "        lm_logits = self.decoder(hidden_state)\n",
        "        return lm_logits\n",
        "\n",
        "class GPT2LMHeadModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GPT2LMHeadModel, self).__init__()\n",
        "        self.transformer = GPT2Model()\n",
        "        self.lm_head = GPT2LMHead(self.transformer.wte.weight)\n",
        "\n",
        "    def set_tied(self):\n",
        "        self.lm_head.set_embeddings_weights(self.transformer.wte.weight)\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\n",
        "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
        "        lm_logits = self.lm_head(hidden_states)\n",
        "        if lm_labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
        "            return loss\n",
        "        return lm_logits, presents"
      ],
      "metadata": {
        "id": "G5cpMbRrCuT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import regex as re\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def bytes_to_unicode():\n",
        "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
        "    cs = bs[:]\n",
        "    n = 0\n",
        "    for b in range(2**8):\n",
        "        if b not in bs:\n",
        "            bs.append(b)\n",
        "            cs.append(2**8+n)\n",
        "            n += 1\n",
        "    cs = [chr(n) for n in cs]\n",
        "    return dict(zip(bs, cs))\n",
        "\n",
        "def get_pairs(word):\n",
        "\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, encoder, bpe_merges, errors='replace'):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
        "        self.errors = errors # how to handle errors in decoding\n",
        "        self.byte_encoder = bytes_to_unicode()\n",
        "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
        "        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\n",
        "        self.cache = {}\n",
        "\n",
        "        # Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\n",
        "        self.pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "\n",
        "    def bpe(self, token):\n",
        "        if token in self.cache:\n",
        "            return self.cache[token]\n",
        "        word = tuple(token)\n",
        "        pairs = get_pairs(word)\n",
        "\n",
        "        if not pairs:\n",
        "            return token\n",
        "\n",
        "        while True:\n",
        "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "            if bigram not in self.bpe_ranks:\n",
        "                break\n",
        "            first, second = bigram\n",
        "            new_word = []\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                try:\n",
        "                    j = word.index(first, i)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                except:\n",
        "                    new_word.extend(word[i:])\n",
        "                    break\n",
        "\n",
        "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                    new_word.append(first+second)\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_word.append(word[i])\n",
        "                    i += 1\n",
        "            new_word = tuple(new_word)\n",
        "            word = new_word\n",
        "            if len(word) == 1:\n",
        "                break\n",
        "            else:\n",
        "                pairs = get_pairs(word)\n",
        "        word = ' '.join(word)\n",
        "        self.cache[token] = word\n",
        "        return word\n",
        "\n",
        "    def encode(self, text):\n",
        "        bpe_tokens = []\n",
        "        for token in re.findall(self.pat, text):\n",
        "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
        "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
        "        return bpe_tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        text = ''.join([self.decoder[token] for token in tokens])\n",
        "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=self.errors)\n",
        "        return text\n",
        "\n",
        "def get_encoder():\n",
        "    with open('encoder.json', 'r') as f:\n",
        "        encoder = json.load(f)\n",
        "    with open('vocab.bpe', 'r', encoding=\"utf-8\") as f:\n",
        "        bpe_data = f.read()\n",
        "    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
        "    return Encoder(\n",
        "        encoder=encoder,\n",
        "        bpe_merges=bpe_merges,\n",
        "    )"
      ],
      "metadata": {
        "id": "FMaBupVnCxWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weight(model, state_dict):\n",
        "    old_keys = []\n",
        "    new_keys = []\n",
        "    for key in state_dict.keys():\n",
        "        new_key = None\n",
        "        if key.endswith(\".g\"):\n",
        "            new_key = key[:-2] + \".weight\"\n",
        "        elif key.endswith(\".b\"):\n",
        "            new_key = key[:-2] + \".bias\"\n",
        "        elif key.endswith(\".w\"):\n",
        "            new_key = key[:-2] + \".weight\"\n",
        "        if new_key:\n",
        "            old_keys.append(key)\n",
        "            new_keys.append(new_key)\n",
        "    for old_key, new_key in zip(old_keys, new_keys):\n",
        "        state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "    missing_keys = []\n",
        "    unexpected_keys = []\n",
        "    error_msgs = []\n",
        "    # copy state_dict so _load_from_state_dict can modify it\n",
        "    metadata = getattr(state_dict, \"_metadata\", None)\n",
        "    state_dict = state_dict.copy()\n",
        "    if metadata is not None:\n",
        "        state_dict._metadata = metadata\n",
        "\n",
        "    def load(module, prefix=\"\"):\n",
        "        local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "        module._load_from_state_dict(\n",
        "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs\n",
        "        )\n",
        "        for name, child in module._modules.items():\n",
        "            if child is not None:\n",
        "                load(child, prefix + name + \".\")\n",
        "\n",
        "    start_model = model\n",
        "    if hasattr(model, \"transformer\") and all(not s.startswith('transformer.') for s in state_dict.keys()):\n",
        "        start_model = model.transformer\n",
        "    load(start_model, prefix=\"\")\n",
        "\n",
        "    # Make sure we are still sharing the output and input embeddings after loading weights\n",
        "    model.set_tied()\n",
        "    return model"
      ],
      "metadata": {
        "id": "4cWY05eKQDnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom = GPT2LMHeadModel()"
      ],
      "metadata": {
        "id": "2C3Swc_javzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Model,GPT2LMHeadModel,GPT2Config\n",
        "\n"
      ],
      "metadata": {
        "id": "y6E43yhsQ9FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPT2Config.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
        "custom_model_weights = load_weight(model_custom, gpt2_model.state_dict())"
      ],
      "metadata": {
        "id": "b7WsBjIL_x71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    code by TaeHwan Jung(@graykode)\n",
        "    Original Paper and repository here : https://github.com/openai/gpt-2\n",
        "    GPT2 Pytorch Model : https://github.com/huggingface/pytorch-pretrained-BERT\n",
        "'''\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import trange\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[:, -1]\n",
        "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
        "\n",
        "def sample_sequence(model, length, start_token=None, batch_size=None, context=None, temperature=1, top_k=0, device='cpu', sample=True):\n",
        "    if start_token is None:\n",
        "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
        "        context = torch.tensor(context, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n",
        "    else:\n",
        "        assert context is None, 'Specify exactly one of start_token and context!'\n",
        "        context = torch.full((batch_size, 1), start_token, device=device, dtype=torch.long)\n",
        "    prev = context\n",
        "    output = context\n",
        "    past = None\n",
        "    with torch.no_grad():\n",
        "        for i in trange(length):\n",
        "            logits, past = model(prev, past=past)\n",
        "            logits = logits[:, -1, :]\n",
        "            logits = top_k_logits(logits, k=top_k)\n",
        "            log_probs = F.softmax(logits, dim=-1)\n",
        "            if sample:\n",
        "                prev = torch.multinomial(log_probs, num_samples=1)\n",
        "            else:\n",
        "                _, prev = torch.topk(log_probs, k=1, dim=-1)\n",
        "            output = torch.cat((output, prev), dim=1)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "text = \"Once upon a time\"\n",
        "context_tokens = get_encoder().encode(text)\n",
        "\n",
        "out = sample_sequence(\n",
        "            model=custom_model_weights, length=80,\n",
        "            context=context_tokens , batch_size = 1, top_k=1, device='cpu'\n",
        "        )\n"
      ],
      "metadata": {
        "id": "xKvbat7uRUI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = get_encoder()\n",
        "enc.decode(out[0].tolist())"
      ],
      "metadata": {
        "id": "MnlpDr3LATf1",
        "outputId": "d3381c11-9e63-40c3-df0d-495fb7c8d877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Reference: https://github.com/graykode/gpt-2-Pytorch\""
      ],
      "metadata": {
        "id": "TBYrKZ5UWewh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task -2"
      ],
      "metadata": {
        "id": "HqhV5EeeB6MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "\n",
        "# Load pre-trained GPT-2 model and its configuration\n",
        "gpt2_config = GPT2Config.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', config=gpt2_config)\n",
        "\n",
        "# Extract the embedding layer from the GPT-2 model\n",
        "\n",
        "\n",
        "# Now you have the GPT-2 model with the rotary embedding incorporated into its language modeling head\n",
        "\n",
        "model_state_dict = gpt2_model.state_dict()\n",
        "for param_name, param in model_state_dict.items():\n",
        "    print(f\"Parameter: {param_name}, Shape: {param.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "from math import pi, log\n",
        "\n",
        "import torch\n",
        "from torch.cuda.amp import autocast\n",
        "from torch import nn, einsum, broadcast_tensors\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def broadcat(tensors, dim = -1):\n",
        "    broadcasted_tensors = broadcast_tensors(*tensors)\n",
        "    return torch.cat(broadcasted_tensors, dim = dim)\n",
        "\n",
        "# rotary embedding helper functions\n",
        "\n",
        "def rotate_half(x):\n",
        "    x = rearrange(x, '... (d r) -> ... d r', r = 2)\n",
        "    x1, x2 = x.unbind(dim = -1)\n",
        "    x = torch.stack((-x2, x1), dim = -1)\n",
        "    return rearrange(x, '... d r -> ... (d r)')\n",
        "\n",
        "@autocast(enabled = False)\n",
        "def apply_rotary_emb(freqs, t, start_index = 0, scale = 1., seq_dim = -2):\n",
        "    rot_dim, seq_len = freqs.shape[-1], t.shape[seq_dim]\n",
        "    freqs = freqs[-seq_len:].to(t)\n",
        "\n",
        "    end_index = start_index + rot_dim\n",
        "    assert rot_dim <= t.shape[-1], f'feature dimension {t.shape[-1]} is not of sufficient size to rotate in all the positions {rot_dim}'\n",
        "    t_left, t, t_right = t[..., :start_index], t[..., start_index:end_index], t[..., end_index:]\n",
        "    t = (t * freqs.cos() * scale) + (rotate_half(t) * freqs.sin() * scale)\n",
        "    return torch.cat((t_left, t, t_right), dim = -1)\n",
        "\n",
        "# learned rotation helpers\n",
        "\n",
        "def apply_learned_rotations(rotations, t, start_index = 0, freq_ranges = None):\n",
        "    if exists(freq_ranges):\n",
        "        rotations = einsum('..., f -> ... f', rotations, freq_ranges)\n",
        "        rotations = rearrange(rotations, '... r f -> ... (r f)')\n",
        "\n",
        "    rotations = repeat(rotations, '... n -> ... (n r)', r = 2)\n",
        "    return apply_rotary_emb(rotations, t, start_index = start_index)\n",
        "\n",
        "# classes\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        custom_freqs = None,\n",
        "        freqs_for = 'lang',\n",
        "        theta = 10000,\n",
        "        max_freq = 10,\n",
        "        num_freqs = 1,\n",
        "        learned_freq = False,\n",
        "        use_xpos = False,\n",
        "        xpos_scale_base = 512,\n",
        "        interpolate_factor = 1.,\n",
        "        theta_rescale_factor = 1.,\n",
        "        seq_before_head_dim = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # proposed by reddit user bloc97, to rescale rotary embeddings to longer sequence length without fine-tuning\n",
        "        # has some connection to NTK literature\n",
        "        # https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/\n",
        "\n",
        "        theta *= theta_rescale_factor ** (dim / (dim - 2))\n",
        "\n",
        "        if exists(custom_freqs):\n",
        "            freqs = custom_freqs\n",
        "        elif freqs_for == 'lang':\n",
        "            freqs = 1. / (theta ** (torch.arange(0, dim, 2)[:(dim // 2)].float() / dim))\n",
        "        elif freqs_for == 'pixel':\n",
        "            freqs = torch.linspace(1., max_freq / 2, dim // 2) * pi\n",
        "        elif freqs_for == 'constant':\n",
        "            freqs = torch.ones(num_freqs).float()\n",
        "        else:\n",
        "            raise ValueError(f'unknown modality {freqs_for}')\n",
        "\n",
        "        self.cache = dict()\n",
        "        self.cache_scale = dict()\n",
        "        self.freqs = nn.Parameter(freqs, requires_grad = learned_freq)\n",
        "\n",
        "        self.learned_freq = learned_freq\n",
        "\n",
        "        # default sequence dimension\n",
        "\n",
        "        self.seq_before_head_dim = seq_before_head_dim\n",
        "        self.default_seq_dim = -3 if seq_before_head_dim else -2\n",
        "\n",
        "        # interpolation factors\n",
        "\n",
        "        assert interpolate_factor >= 1.\n",
        "        self.interpolate_factor = interpolate_factor\n",
        "\n",
        "        # xpos\n",
        "\n",
        "        self.use_xpos = use_xpos\n",
        "        if not use_xpos:\n",
        "            self.register_buffer('scale', None)\n",
        "            return\n",
        "\n",
        "        scale = (torch.arange(0, dim, 2) + 0.4 * dim) / (1.4 * dim)\n",
        "        self.scale_base = xpos_scale_base\n",
        "        self.register_buffer('scale', scale)\n",
        "\n",
        "    def get_seq_pos(self, seq_len, device, dtype, offset = 0):\n",
        "        return (torch.arange(seq_len, device = device, dtype = dtype) + offset) / self.interpolate_factor\n",
        "\n",
        "    def rotate_queries_or_keys(self, t, seq_dim = None, offset = 0, freq_seq_len = None):\n",
        "        seq_dim = default(seq_dim, self.default_seq_dim)\n",
        "\n",
        "        assert not self.use_xpos, 'you must use `.rotate_queries_and_keys` method instead and pass in both queries and keys, for length extrapolatable rotary embeddings'\n",
        "\n",
        "        device, dtype, seq_len = t.device, t.dtype, t.shape[seq_dim]\n",
        "\n",
        "        if exists(freq_seq_len):\n",
        "            assert freq_seq_len >= seq_len\n",
        "            seq_len = freq_seq_len\n",
        "\n",
        "        freqs = self.forward(lambda: self.get_seq_pos(seq_len, device = device, dtype = dtype, offset = offset), cache_key = f'freqs:{seq_len}|offset:{offset}')\n",
        "\n",
        "        if seq_dim == -3:\n",
        "            freqs = rearrange(freqs, 'n d -> n 1 d')\n",
        "\n",
        "        return apply_rotary_emb(freqs, t, seq_dim = seq_dim)\n",
        "\n",
        "    def rotate_queries_with_cached_keys(self, q, k, seq_dim = None, offset = 0):\n",
        "        seq_dim = default(seq_dim, self.default_seq_dim)\n",
        "\n",
        "        q_len, k_len = q.shape[seq_dim], k.shape[seq_dim]\n",
        "        assert q_len <= k_len\n",
        "        rotated_q = self.rotate_queries_or_keys(q, seq_dim = seq_dim, freq_seq_len = k_len)\n",
        "        rotated_k = self.rotate_queries_or_keys(k, seq_dim = seq_dim)\n",
        "\n",
        "        rotated_q = rotated_q.type(q.dtype)\n",
        "        rotated_k = rotated_k.type(k.dtype)\n",
        "\n",
        "        return rotated_q, rotated_k\n",
        "\n",
        "    def rotate_queries_and_keys(self, q, k, seq_dim = None):\n",
        "        seq_dim = default(seq_dim, self.default_seq_dim)\n",
        "\n",
        "        assert self.use_xpos\n",
        "        device, dtype, seq_len = q.device, q.dtype, q.shape[seq_dim]\n",
        "\n",
        "        seq = self.get_seq_pos(seq_len, dtype = dtype, device = device)\n",
        "        freqs = self.forward(lambda: seq, cache_key = f'freqs:{seq_len}')\n",
        "        scale = self.get_scale(lambda: seq, cache_key = f'scale:{seq_len}').to(dtype)\n",
        "\n",
        "        if seq_dim == -3:\n",
        "            freqs = rearrange(freqs, 'n d -> n 1 d')\n",
        "            scale = rearrange(scale, 'n d -> n 1 d')\n",
        "\n",
        "        rotated_q = apply_rotary_emb(freqs, q, scale = scale, seq_dim = seq_dim)\n",
        "        rotated_k = apply_rotary_emb(freqs, k, scale = scale ** -1, seq_dim = seq_dim)\n",
        "\n",
        "        rotated_q = rotated_q.type(q.dtype)\n",
        "        rotated_k = rotated_k.type(k.dtype)\n",
        "\n",
        "        return rotated_q, rotated_k\n",
        "\n",
        "    def get_scale(self, t, cache_key = None):\n",
        "        assert self.use_xpos\n",
        "\n",
        "        if exists(cache_key) and cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        if callable(t):\n",
        "            t = t()\n",
        "\n",
        "        scale = 1.\n",
        "        if self.use_xpos:\n",
        "            power = (t - len(t) // 2) / self.scale_base\n",
        "            scale = self.scale ** rearrange(power, 'n -> n 1')\n",
        "            scale = torch.cat((scale, scale), dim = -1)\n",
        "\n",
        "        if exists(cache_key):\n",
        "            self.cache[cache_key] = scale\n",
        "\n",
        "        return scale\n",
        "\n",
        "    @autocast(enabled = False)\n",
        "    def forward(self, t, cache_key = None):\n",
        "        should_cache = not self.learned_freq and exists(cache_key)\n",
        "\n",
        "        if should_cache and cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        if callable(t):\n",
        "            t = t()\n",
        "\n",
        "        freqs = self.freqs\n",
        "\n",
        "        freqs = einsum('..., f -> ... f', t.type(freqs.dtype), freqs)\n",
        "        freqs = repeat(freqs, '... n -> ... (n r)', r = 2)\n",
        "\n",
        "        if should_cache:\n",
        "            self.cache[cache_key] = freqs\n",
        "\n",
        "        return freqs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "custom_model_weights.transformer.wpe = RotaryEmbedding(768)\n",
        "\n",
        "\n",
        "\n",
        "model_state = gpt2_model.state_dict()\n",
        "for param_name, param in model_state.items():\n",
        "    print(f\"Parameter: {param_name}, Shape: {param.shape}\")\n",
        "\n",
        "model_state_dict = custom_model_weights.state_dict()\n",
        "for param_name, param in model_state_dict.items():\n",
        "    print(f\"Parameter: {param_name}, Shape: {param.shape}\")\n",
        "\n",
        "\n",
        "'''\n",
        "    code by TaeHwan Jung(@graykode)\n",
        "    Original Paper and repository here : https://github.com/openai/gpt-2\n",
        "    GPT2 Pytorch Model : https://github.com/huggingface/pytorch-pretrained-BERT\n",
        "'''\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import trange\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[:, -1]\n",
        "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
        "\n",
        "def sample_sequence(model, length, start_token=None, batch_size=None, context=None, temperature=1, top_k=0, device='cpu', sample=True):\n",
        "    if start_token is None:\n",
        "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
        "        context = torch.tensor(context, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n",
        "    else:\n",
        "        assert context is None, 'Specify exactly one of start_token and context!'\n",
        "        context = torch.full((batch_size, 1), start_token, device=device, dtype=torch.long)\n",
        "    prev = context\n",
        "    output = context\n",
        "    past = None\n",
        "    with torch.no_grad():\n",
        "        for i in trange(length):\n",
        "            logits, past = model(prev, past=past)\n",
        "            logits = logits[:, -1, :]\n",
        "            logits = top_k_logits(logits, k=top_k)\n",
        "            log_probs = F.softmax(logits, dim=-1)\n",
        "            if sample:\n",
        "                prev = torch.multinomial(log_probs, num_samples=1)\n",
        "            else:\n",
        "                _, prev = torch.topk(log_probs, k=1, dim=-1)\n",
        "            output = torch.cat((output, prev), dim=1)\n",
        "    return output\n",
        "\n",
        "\n",
        "text = \"Once upon a time\"\n",
        "context_tokens = get_encoder().encode(text)\n",
        "\n",
        "out = sample_sequence(\n",
        "            model=custom_model_weights, length=80,\n",
        "            context=context_tokens , batch_size = 1, top_k=1, device='cpu'\n",
        "        )\n",
        "\n",
        "enc = get_encoder()\n",
        "\n",
        "print(enc.decode(out[0].tolist()))\n",
        "\"Reference : https://github.com/lucidrains/rotary-embedding-torch/blob/main/rotary_embedding_torch/rotary_embedding_torch.py\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7UbtLWb_BqPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Group Query Attention\n",
        "#Modified attention function for grouped query  2 grups are defined\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, scale=False, num_groups=2):\n",
        "        super(Attention, self).__init__()\n",
        "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
        "        assert n_state % 12 == 0\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.n_head = 12\n",
        "        self.split_size = n_state\n",
        "        self.num_groups = num_groups  # Number of query groups\n",
        "        self.scale = scale\n",
        "        self.c_attn = Conv1D(n_state * 3, nx)\n",
        "        self.c_proj = Conv1D(n_state, nx)\n",
        "\n",
        "    def _grouped_attn(self, q, k, v):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        b = self.bias[:, :, ns-nd:ns, :ns]\n",
        "        w = w * b - 1e10 * (1 - b)\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        return torch.matmul(w, v)\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def group_queries(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_groups, x.size(-1) // self.num_groups)\n",
        "        return x.view(*new_x_shape)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "\n",
        "        # Group queries\n",
        "        query = self.group_queries(query)\n",
        "\n",
        "        query = self.split_heads(query)\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "\n",
        "        present = torch.stack((key.transpose(-2, -1), value))\n",
        "\n",
        "        a = self._grouped_attn(query, key, value)\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "\n",
        "        return a, present\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Sliding window attention\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, scale=False, window_size=128):\n",
        "        super(Attention, self).__init__()\n",
        "        n_state = nx\n",
        "        assert n_state % 12 == 0\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.n_head = 12\n",
        "        self.split_size = n_state\n",
        "        self.window_size = window_size  # Define the sliding window size\n",
        "        self.scale = scale\n",
        "        self.c_attn = Conv1D(n_state * 3, nx)\n",
        "        self.c_proj = Conv1D(n_state, nx)\n",
        "\n",
        "    def _sliding_window_attn(self, q, k, v):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "\n",
        "        # Apply sliding window mask\n",
        "        mask = torch.triu(torch.ones(nd, ns), diagonal=self.window_size)\n",
        "        mask = mask.unsqueeze(0).unsqueeze(0).to(w.device)\n",
        "\n",
        "        w = w.masked_fill(mask == 0, float('-inf'))\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        return torch.matmul(w, v)\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "        query = self.split_heads(query)\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "\n",
        "        present = torch.stack((key.transpose(-2, -1), value))\n",
        "\n",
        "        a = self._sliding_window_attn(query, key, value)\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "\n",
        "        return a, present\n"
      ],
      "metadata": {
        "id": "iN08oOunDHfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task-3\n",
        "\n",
        "#single GPU\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "model = custom_model_weights\n",
        "\n",
        "# Define optimizer and criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Dummy input data and labels\n",
        "input_data = torch.randn(100, 10)\n",
        "labels = torch.randint(0, 2, (100,))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    model.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_data)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/5], Loss: {loss.item()}\")\n",
        "\n",
        "# Optionally, save the trained model\n",
        "torch.save(model.state_dict(), 'trained_model.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#DDP\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "\n",
        "    # initialize the process group\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\n",
        "\n",
        "def demo_basic(rank, world_size):\n",
        "    print(f\"Running basic DDP example on rank {rank}.\")\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    # create model and move it to GPU with id rank\n",
        "    model = custom_model_weights()\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "    optimizer = optim.Adam(ddp_model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    input_data = torch.randn(100, 10)\n",
        "    labels = torch.randint(0, 2, (100,))\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(\"number of epoch\"):\n",
        "        optimizer.zero_grad()\n",
        "        output = ddp_model(input_data)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Rank {rank}: Epoch [{epoch + 1}/5], Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "    cleanup()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    world_size = x  # Number of processes\n",
        "    mp.spawn(demo_basic, args=(world_size, ), nprocs=world_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#FSDP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import fairscale\n",
        "\n",
        "\n",
        "# Create your model\n",
        "model = custom_model_weights()\n",
        "\n",
        "# Wrap the model with FSDP\n",
        "model = fairscale.nn.wrap_model(model)\n",
        "\n",
        "# Define optimizer and criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Dummy input data and labels\n",
        "input_data = torch.randn(100, 10)\n",
        "labels = torch.randint(0, 2, (100,))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    model.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_data)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/5], Loss: {loss.item()}\")\n",
        "\n",
        "# Optionally, save the trained model\n",
        "torch.save(model.module.state_dict(), 'trained_model_fsdp.pth')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qrs55jIYCFiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}